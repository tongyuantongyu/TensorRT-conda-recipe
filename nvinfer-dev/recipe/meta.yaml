{% set version = "8.6.1.6" %}
{% set cuda_version = "12.0" %}
# {% set cudnn_version = "8.6" %}

package:
  name: libnvinfer-dev
  version: {{ version }}

source:
  - path: ../../src_win64  # [win]
  - path: ../../src_linux64  # [linux]
  - path: ../../license

requirements:
  build:
    - m2-unzip  # [win]
  run:
    - libnvinfer  ={{version}}
  run_exports:
    - libnvinfer  ={{version}}

build:
  number: 0
  script:
    - unzip TensorRT-{{ version }}.Windows10.x86_64.cuda-{{ cuda_version }}.zip  # [win]
    - tar xvf TensorRT-{{ version }}.Linux.x86_64-gnu.cuda-{{ cuda_version }}.tar.gz  # [linux]
    - mkdir -p $PREFIX/include             # [linux]
    - cp TensorRT-{{ version }}/include/*.h $PREFIX/include/      # [linux]
    - mkdir %LIBRARY_INC%                                # [win]
    - copy %SRC_DIR%\\TensorRT-{{ version }}\\include\\*.h %LIBRARY_INC%\\  # [win]
    - mkdir %LIBRARY_LIB%                                # [win]
    - copy %SRC_DIR%\\TensorRT-{{ version }}\\lib\\*.lib %LIBRARY_LIB%\\    # [win]
  test:
    commands:
      - if not exist %LIBRARY_INC%/NvInfer.h exit 1        # [win]
      - if not exist %LIBRARY_INC%/NvOnnxParser.h exit 1  # [win]
      - if not exist %LIBRARY_LIB%/nvinfer.lib exit 1      # [win]
      - if not exist %LIBRARY_LIB%/nvonnxparser.lib exit 1      # [win]
      - test -f $PREFIX/include/NvInfer.h                  # [linux]
      - test -f $PREFIX/include/NvOnnxParser.h                  # [linux]
about:
  home: https://developer.nvidia.com/tensorrt
  license: LicenseRef-TensorRT-Software-License-Agreement
  license_file: TensorRT-SLA.pdf
  license_url: https://docs.nvidia.com/deeplearning/tensorrt/sla/index.html
  summary: "NVIDIA's TensorRT deep neural network inference library"
  description: |
    PLEASE IMFORM ME TO DELETE THIS PACKAGE.

    This is the SDK package that contains files necessary for build but process
    but can not be distributed as per EULA.

    NVIDIA® TensorRT™ is an SDK for optimizing-trained deep learning models
    to enable high-performance inference. TensorRT contains a deep learning
    inference optimizer for trained deep learning models, and a runtime for
    execution.

    License Agreements:- The packages are governed by the NVIDIA TensorRT
    Software License Agreement (EULA). By downloading and using the packages,
    you accept the terms and conditions of the NVIDIA TensorRT EULA -
    https://docs.nvidia.com/deeplearning/tensorrt/sla/index.html
  doc_url: https://docs.nvidia.com/deeplearning/tensorrt/
  dev_url: https://developer.nvidia.com/nvidia-tensorrt-download

extra:
  recipe-maintainers:
    - tongyuantongyu